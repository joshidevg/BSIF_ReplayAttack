{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the Data and making a CSV file using it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hist(img):\n",
    "    histogram = [0] * 3\n",
    "    for j in range(3):\n",
    "        histr = cv2.calcHist([img], [j], None, [256], [0, 256])\n",
    "        histr *= 255.0 / histr.max()\n",
    "        histogram[j] = histr\n",
    "    return np.array(histogram).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hist(image_path):\n",
    "    # read the image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # convert the image to YCrCb color space\n",
    "    ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # convert the image to LUV color space\n",
    "    luv = cv2.cvtColor(img, cv2.COLOR_BGR2Luv)\n",
    "\n",
    "    # calculate the histograms\n",
    "    ycrcb_hist = calc_hist(ycrcb)\n",
    "    luv_hist = calc_hist(luv)\n",
    "\n",
    "    return ycrcb_hist, luv_hist, np.append(ycrcb_hist.ravel(), luv_hist.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pictures(folder_path1, folder_path2):\n",
    "    hist_list = []\n",
    "    \n",
    "    file_list = os.listdir(folder_path1)\n",
    "    # loop through each file and get its histogram\n",
    "    for file_name in file_list:\n",
    "        if file_name.endswith('.png'):\n",
    "            file_path = os.path.join(folder_path1, file_name)\n",
    "            _, _, hist = get_hist(file_path)\n",
    "            hist_list.append([hist, 1])\n",
    "    \n",
    "    file_list = os.listdir(folder_path2)\n",
    "    # loop through each file and get its histogram\n",
    "    for file_name in file_list:\n",
    "        if file_name.endswith('.png'):\n",
    "            file_path = os.path.join(folder_path2, file_name)\n",
    "            _, _, hist = get_hist(file_path)\n",
    "            hist_list.append([hist, -1])\n",
    "\n",
    "    # store the histograms in a pandas dataframe\n",
    "    df = pd.DataFrame(hist_list, columns=['hist', 'label'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                hist  label\n",
      "0  [0.29209623, 0.0, 0.0, 3.5051546, 0.0, 0.0, 5....      1\n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      1\n",
      "2  [0.0, 0.0, 0.0, 8.525836, 0.0, 0.0, 10.851064,...      1\n",
      "3  [0.0, 0.0, 0.0, 0.2802198, 0.0, 0.0, 0.2802198...      1\n",
      "4  [1.2927756, 0.0, 0.0, 13.25095, 0.0, 0.0, 19.7...      1\n",
      "                                                hist  label\n",
      "0  [0.29209623, 0.0, 0.0, 3.5051546, 0.0, 0.0, 5....      1\n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      1\n",
      "2  [0.0, 0.0, 0.0, 8.525836, 0.0, 0.0, 10.851064,...      1\n",
      "3  [0.0, 0.0, 0.0, 0.2802198, 0.0, 0.0, 0.2802198...      1\n",
      "4  [1.2927756, 0.0, 0.0, 13.25095, 0.0, 0.0, 19.7...      1\n"
     ]
    }
   ],
   "source": [
    "small_df = read_pictures('Small_Data/Actual_Pictures', 'Small_Data/Replay_Attack')\n",
    "print(small_df.head())\n",
    "\n",
    "big_df = read_pictures('Big_Data/Actual_Pictures', 'Big_Data/Replay_Attack')\n",
    "print(big_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_csv(df, filename):\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"{filename} already exists. Exiting without writing.\")\n",
    "        return\n",
    "    # create a new dataframe with 1536 columns\n",
    "    new_df = pd.DataFrame(df.iloc[:, 0].tolist(), columns=[f'feature{i}' for i in range(1, 1537)])\n",
    "    \n",
    "    # add the label column to the new dataframe\n",
    "    new_df['label'] = df.iloc[:, 1]\n",
    "    \n",
    "    # write the new dataframe to a csv file\n",
    "    new_df.to_csv(filename, index=False)\n",
    "    \n",
    "    print(f\"{filename} saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_histograms.csv saved successfully.\n",
      "big_histograms.csv saved successfully.\n"
     ]
    }
   ],
   "source": [
    "df_to_csv(small_df, 'small_histograms.csv')\n",
    "df_to_csv(big_df, 'big_histograms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def shuffle_and_split_csv(input_file, train_file, test_file, test_size=0.2):\n",
    "    # read the csv file\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # shuffle the dataframe\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # split the dataframe into training and testing sets\n",
    "    train, test = train_test_split(df, test_size=test_size, random_state=42)\n",
    "\n",
    "    # write the training and testing sets to csv files\n",
    "    train.to_csv(train_file, index=False)\n",
    "    test.to_csv(test_file, index=False)\n",
    "\n",
    "    print(\"Data shuffled and split into training.csv and testing.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shuffled and split into training.csv and testing.csv\n",
      "Data shuffled and split into training.csv and testing.csv\n"
     ]
    }
   ],
   "source": [
    "shuffle_and_split_csv('small_histograms.csv', 'small_training.csv', 'small_testing.csv', 0.3)\n",
    "shuffle_and_split_csv('big_histograms.csv', 'big_training.csv', 'big_testing.csv', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shuffled and split into training.csv and testing.csv\n"
     ]
    }
   ],
   "source": [
    "shuffle_and_split_csv('small_bsif.csv', 'small_bsif_training.csv', 'small_bsif_testing.csv', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
